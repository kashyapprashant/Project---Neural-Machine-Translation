{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "51TuwoYm0UFl"
   },
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TDw0PwyH1aH4"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g4MDcKWQ2pVh"
   },
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fgNAwT6i25kK"
   },
   "outputs": [],
   "source": [
    "data = read_text(\"fra.txt\")\n",
    "fra_eng = to_lines(data)\n",
    "fra_eng = array(fra_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OS1r9mBIP_aH",
    "outputId": "d27277c9-07cc-401f-df07-02864613c7e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192341"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fra_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAzN3Vs-4QiS",
    "outputId": "5eadbb34-893d-41e2-ad87-39c3aae10137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Va !'],\n",
       "       ['Go.', 'Marche.'],\n",
       "       ['Go.', 'Bouge !'],\n",
       "       ...,\n",
       "       [\"I don't want to sing anymore.\", 'Je ne veux plus chanter.'],\n",
       "       [\"I don't want to stay at home.\",\n",
       "        \"Je n'ai pas envie de rester à la maison.\"],\n",
       "       [\"I don't want to stay at home.\",\n",
       "        'Je ne veux pas rester chez moi.']], dtype='<U349')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_eng=fra_eng[:100000,:2]\n",
    "fra_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqln0L_H4fMz",
    "outputId": "2e00a6f4-6f9e-47aa-df4c-4a09072f2d26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Va '],\n",
       "       ['Go', 'Marche'],\n",
       "       ['Go', 'Bouge '],\n",
       "       ...,\n",
       "       ['I dont want to sing anymore', 'Je ne veux plus chanter'],\n",
       "       ['I dont want to stay at home',\n",
       "        'Je nai pas envie de rester à la maison'],\n",
       "       ['I dont want to stay at home', 'Je ne veux pas rester chez moi']],\n",
       "      dtype='<U349')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "fra_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,0]]\n",
    "fra_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,1]]\n",
    "\n",
    "fra_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KN7ESegK5eSd",
    "outputId": "8c06b3b1-7699-4015-b0be-903a81182932"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 'va '],\n",
       "       ['go', 'marche'],\n",
       "       ['go', 'bouge '],\n",
       "       ...,\n",
       "       ['i dont want to sing anymore', 'je ne veux plus chanter'],\n",
       "       ['i dont want to stay at home',\n",
       "        'je nai pas envie de rester à la maison'],\n",
       "       ['i dont want to stay at home', 'je ne veux pas rester chez moi']],\n",
       "      dtype='<U349')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(fra_eng)):\n",
    "    fra_eng[i,0] = fra_eng[i,0].lower()\n",
    "    fra_eng[i,1] = fra_eng[i,1].lower()\n",
    "\n",
    "fra_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V4kyo0z-5z4G"
   },
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "fra_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in fra_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in fra_eng[:,1]:\n",
    "      fra_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soeFDkGV76eu",
    "outputId": "d6e17f0f-e803-47e2-c69e-730fa5fb3806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 14\n"
     ]
    }
   ],
   "source": [
    "print(max(eng_l),max(fra_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OR40F3HT6SoX"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WO1NoWu6dnV",
    "outputId": "771d7013-9c83-4575-8341-414e7bb8ea90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9165\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(fra_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = max(eng_l)\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1kbD0YZ6oiV",
    "outputId": "37755b34-9538-45a0-e00b-e2004c0e770b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 21655\n"
     ]
    }
   ],
   "source": [
    "# prepare French tokenizer\n",
    "fra_tokenizer = tokenization(fra_eng[:, 1])\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "\n",
    "fra_length = max(fra_l)\n",
    "print('Deutch Vocabulary Size: %d' % fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DeeQTWUI68j_"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvwE1A-o7IaE"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ohMy2ml57QDy"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(fra_eng, test_size=0.1, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Fx02IYrO7ZaS"
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(fra_tokenizer, fra_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(fra_tokenizer, fra_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yNS4Qt9S9AJS"
   },
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NSwRnLsa9GVx"
   },
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PPv-iGz9NIb",
    "outputId": "ee36bca7-21b3-47f3-cd63-bf5b922408d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "rms = keras.optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXQ5I6OIB0Re",
    "outputId": "aacc373a-1c23-4936-b14b-c4ab448e1f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "141/141 [==============================] - 35s 173ms/step - loss: 3.7383 - acc: 0.4766 - val_loss: 3.4055 - val_acc: 0.4902\n",
      "Epoch 2/30\n",
      "141/141 [==============================] - 22s 159ms/step - loss: 3.2193 - acc: 0.5067 - val_loss: 3.1044 - val_acc: 0.5153\n",
      "Epoch 3/30\n",
      "141/141 [==============================] - 23s 160ms/step - loss: 2.9105 - acc: 0.5365 - val_loss: 2.7853 - val_acc: 0.5592\n",
      "Epoch 4/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 2.6012 - acc: 0.5769 - val_loss: 2.5554 - val_acc: 0.5911\n",
      "Epoch 5/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 2.3571 - acc: 0.6064 - val_loss: 2.3622 - val_acc: 0.6131\n",
      "Epoch 6/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 2.1501 - acc: 0.6294 - val_loss: 2.2197 - val_acc: 0.6305\n",
      "Epoch 7/30\n",
      "141/141 [==============================] - 23s 164ms/step - loss: 1.9680 - acc: 0.6495 - val_loss: 2.0750 - val_acc: 0.6463\n",
      "Epoch 8/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 1.8055 - acc: 0.6677 - val_loss: 1.9813 - val_acc: 0.6586\n",
      "Epoch 9/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 1.6581 - acc: 0.6857 - val_loss: 1.8868 - val_acc: 0.6701\n",
      "Epoch 10/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 1.5199 - acc: 0.7027 - val_loss: 1.8026 - val_acc: 0.6806\n",
      "Epoch 11/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 1.3938 - acc: 0.7203 - val_loss: 1.7168 - val_acc: 0.6938\n",
      "Epoch 12/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 1.2783 - acc: 0.7378 - val_loss: 1.6612 - val_acc: 0.7025\n",
      "Epoch 13/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 1.1720 - acc: 0.7551 - val_loss: 1.6099 - val_acc: 0.7103\n",
      "Epoch 14/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 1.0743 - acc: 0.7712 - val_loss: 1.5614 - val_acc: 0.7178\n",
      "Epoch 15/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 0.9837 - acc: 0.7881 - val_loss: 1.5465 - val_acc: 0.7218\n",
      "Epoch 16/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.9007 - acc: 0.8030 - val_loss: 1.5013 - val_acc: 0.7265\n",
      "Epoch 17/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.8249 - acc: 0.8180 - val_loss: 1.4671 - val_acc: 0.7330\n",
      "Epoch 18/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.7544 - acc: 0.8318 - val_loss: 1.4475 - val_acc: 0.7407\n",
      "Epoch 19/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.6881 - acc: 0.8450 - val_loss: 1.4341 - val_acc: 0.7421\n",
      "Epoch 20/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.6299 - acc: 0.8574 - val_loss: 1.4183 - val_acc: 0.7465\n",
      "Epoch 21/30\n",
      "141/141 [==============================] - 23s 162ms/step - loss: 0.5750 - acc: 0.8689 - val_loss: 1.4244 - val_acc: 0.7436\n",
      "Epoch 22/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.5249 - acc: 0.8792 - val_loss: 1.4093 - val_acc: 0.7495\n",
      "Epoch 23/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.4761 - acc: 0.8906 - val_loss: 1.4102 - val_acc: 0.7511\n",
      "Epoch 24/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.4344 - acc: 0.8993 - val_loss: 1.4092 - val_acc: 0.7536\n",
      "Epoch 25/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.3950 - acc: 0.9079 - val_loss: 1.4213 - val_acc: 0.7544\n",
      "Epoch 26/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.3599 - acc: 0.9159 - val_loss: 1.4263 - val_acc: 0.7575\n",
      "Epoch 27/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.3281 - acc: 0.9229 - val_loss: 1.4276 - val_acc: 0.7568\n",
      "Epoch 28/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.2985 - acc: 0.9298 - val_loss: 1.4473 - val_acc: 0.7582\n",
      "Epoch 29/30\n",
      "141/141 [==============================] - 23s 161ms/step - loss: 0.2726 - acc: 0.9353 - val_loss: 1.4453 - val_acc: 0.7580\n",
      "Epoch 30/30\n",
      "141/141 [==============================] - 23s 160ms/step - loss: 0.2488 - acc: 0.9406 - val_loss: 1.4532 - val_acc: 0.7581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7e4c80810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2, \n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7n6YV8c8RvV"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWHlqarXMZkT"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tuMKCaruTltW"
   },
   "outputs": [],
   "source": [
    "new=[]\n",
    "for i in range(len(preds)):\n",
    "  new.append(argmax(preds[i],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykGqbgrpUatn",
    "outputId": "98b39d79-703a-4320-d629-a36504b1a056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new=np.array(new)\n",
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CFA0CAVqO6AB"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5j8_gjFUQFmh"
   },
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in new:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9h6vYLBvXafR"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "061Z5VUyYNzX",
    "outputId": "c7fccee3-5957-454e-a9a9-cc41349658a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-619f3769-7b02-4c25-a446-1770c834ecf8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>i just got here last week</td>\n",
       "      <td>i only here  night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>he works in a bank</td>\n",
       "      <td>he is working in a bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>you never asked why</td>\n",
       "      <td>you never  you why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>the proof is trivial</td>\n",
       "      <td>the toilet is defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>she loves shopping</td>\n",
       "      <td>she loves shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>he asked her some questions</td>\n",
       "      <td>he asked out a few</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>everyone looked puzzled</td>\n",
       "      <td>everyone looked puzzled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>tom continued working</td>\n",
       "      <td>tom kept working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>we dont have a garden</td>\n",
       "      <td>we dont have a garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9628</th>\n",
       "      <td>its getting bigger</td>\n",
       "      <td>he is from up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>you cant intimidate us</td>\n",
       "      <td>you cant us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>never trust tom</td>\n",
       "      <td>never trust  tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>tom doesnt want to see you</td>\n",
       "      <td>tom doesnt want to see you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>he opened the cages</td>\n",
       "      <td>he sold the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>its a famous song</td>\n",
       "      <td>he is a real woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-619f3769-7b02-4c25-a446-1770c834ecf8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-619f3769-7b02-4c25-a446-1770c834ecf8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-619f3769-7b02-4c25-a446-1770c834ecf8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                           actual                     predicted\n",
       "2510    i just got here last week         i only here  night   \n",
       "5436           he works in a bank     he is working in a bank  \n",
       "2975          you never asked why         you never  you why   \n",
       "6330         the proof is trivial   the toilet is defective    \n",
       "2390           she loves shopping       she loves shopping     \n",
       "8948  he asked her some questions         he asked out a few   \n",
       "8860      everyone looked puzzled  everyone looked puzzled     \n",
       "5898        tom continued working         tom kept working     \n",
       "4595        we dont have a garden      we dont have a garden   \n",
       "9628           its getting bigger             he is from up    \n",
       "4740       you cant intimidate us              you cant us     \n",
       "7136              never trust tom          never trust  tom    \n",
       "2145   tom doesnt want to see you  tom doesnt want to see you  \n",
       "7937          he opened the cages              he sold the     \n",
       "6814            its a famous song         he is a real woman   "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XGE_JNuvZ03G"
   },
   "outputs": [],
   "source": [
    "ref=[]\n",
    "cand=[]\n",
    "for i in range(len(test)):\n",
    "    ref.append(test[i][0].split())\n",
    "    cand.append(preds_text[i].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWXKusG48zeU"
   },
   "source": [
    "## Calculating BLUE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oo8G8Cs1kqPJ",
    "outputId": "3971391d-0f26-4934-d26b-f44e15456724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5330622548958478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# two references for one document\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "score = corpus_bleu(ref, cand)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Machine Translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
